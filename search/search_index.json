{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"HCBench","text":"<p>Welcome to the official documentation of HCBench.</p>"},{"location":"#overview","title":"\ud83d\uddfa\ufe0f Overview","text":"<p><code>hcbench</code> is organized around three main components:</p> <ol> <li>HCBench-parser: standardizing CNA results from different callers</li> <li>HCBench-sim: evaluating detection accuracy against simulated ground truth datasets from HCDSIM</li> <li>HCBench-real: assessing pairwise consistency between callers using large-scale real-world datasets</li> </ol>"},{"location":"#installation","title":"\ud83d\udce6 Installation","text":"<pre><code>pip install git+https://github.com/compbioclub/HCBench.git@main\n</code></pre>"},{"location":"#citation","title":"\ud83d\udccc Citation","text":"<p>If you use HCBench in your research, please cite the following paper:</p>"},{"location":"gtbench/","title":"GTBench","text":"<p><code>GTBench</code> is an integrated benchmarking module for evaluating copy number alteration (CNA) results at both single-cell and clone levels.  It provides multiple submodules that assess copy number detection, classification, evolutionary stability, haplotype phasing, and clustering performance.</p>"},{"location":"gtbench/#overview-of-submodules","title":"Overview of Submodules","text":"Submodule Description Core Metrics clusterConsistency Provide a global assessment of clone detection AMI, ARI cloneSizebycluster Evaluate the precision of clone size estimation by comparing predicted cell counts against Ground Truth across different clone scales. Predicted Size cellprofile Assess the heterogeneity and resolution of CNA calling by counting the number of unique genomic profiles identified. Unique Group Profile Count cloneSizebycellprofile <code>cndetect</code> Evaluates copy number (CN) detection accuracy RMSE, ACC, SCC <code>cnclass</code> Calculates CN state classification metrics AUROC, AUPRC, ACC, Precision, Recall, F1 <code>hccnchange</code> Evaluates correctness of CN changes between parent and child clones RMSE, ACC <code>hccnstable</code> Calculates evolutionary CN stability along the phylogenetic tree ACC <code>hconsetacc</code> Checks if CN events are detected at the correct branch of evolution ACC <code>hconsetcn</code> Evaluates accuracy of inferred parental CN RMSE, ACC <code>hcPhasing</code> Evaluates haplotype phasing accuracy Mismatch Error, Switch Error <code>mirrorsubclone</code> Evaluates mirror-subclone CNA detection accuracy RMSE, ACC"},{"location":"gtbench/#example-usage","title":"Example Usage","text":"<p>Below is a complete example showing how to initialize and run all major GTBench modules.</p> <pre><code>from hcbench.gtbench.gtbench import GTBench\n\nbench = GTBench(output_dir=\"/path/to/results\")\n\n# 1. CN Detection Benchmark\nbench.cndetect(\n    tool_cna_files=[\n        \"/path/to/signals/haplotype_combined.csv\",\n        \"/path/to/seacon/haplotype_combined.csv\",\n    ],\n    cna_profile_file=\"/path/to/gt/ground_truth_combined_cnv.csv\",\n    tool_names=[\"signals\", \"seacon\"]\n)\n\n# 2. CN Classification Benchmark\nbench.cnclass(\n    tool_hap1_cna_files=[\n        \"/path/to/signals/haplotype_1.csv\",\n        \"/path/to/seacon/haplotype_1.csv\",\n    ],\n    tool_hap2_cna_files=[\n        \"/path/to/signals/haplotype_2.csv\",\n        \"/path/to/seacon/haplotype_2.csv\",\n    ],\n    tool_names=[\"signals\", \"seacon\"],\n    profile_hap1_cna_file=\"/path/to/gt/haplotype_1.csv\",\n    profile_hap2_cna_file=\"/path/to/gt/haplotype_2.csv\",\n    type=\"hcCNA\"\n)\n\n# 3. CN Change Benchmark\nbench.hccnchange(\n    tool_hap1_cna_files=[\n        \"/path/to/signals/haplotype_1.csv\",\n        \"/path/to/seacon/haplotype_1.csv\",\n    ],\n    tool_hap2_cna_files=[\n        \"/path/to/signals/haplotype_2.csv\",\n        \"/path/to/seacon/haplotype_2.csv\",\n    ],\n    tool_names=[\"signals\", \"seacon\"],\n    changes_file=\"/path/to/gt/changes.csv\",\n)\n\n# 4. CN Stability Benchmark\nbench.hccnstable(\n    tool_hap1_cna_files=[\n        \"/path/to/signals/haplotype_1.csv\",\n        \"/path/to/seacon/haplotype_1.csv\",\n    ],\n    tool_hap2_cna_files=[\n        \"/path/to/signals/haplotype_2.csv\",\n        \"/path/to/seacon/haplotype_2.csv\",\n    ],\n    tool_names=[\"signals\", \"seacon\"],\n    changes_file=\"/path/to/gt/changes.csv\",\n    tree_file=\"/path/to/gt/tree.newick\",\n)\n\n# 5. CN Onset Accuracy Benchmark\nbench.hconsetacc(\n    tool_hap1_cna_files=[\n        \"/path/to/signals/haplotype_1.csv\",\n        \"/path/to/seacon/haplotype_1.csv\",\n    ],\n    tool_hap2_cna_files=[\n        \"/path/to/signals/haplotype_2.csv\",\n        \"/path/to/seacon/haplotype_2.csv\",\n    ],\n    tool_names=[\"signals\", \"seacon\"],\n    changes_file=\"/path/to/gt/changes.csv\",\n)\n\n# 6. Parental CN Accuracy Benchmark\nbench.hconsetcn(\n    tool_hap1_cna_files=[\n        \"/path/to/signals/haplotype_1.csv\",\n        \"/path/to/seacon/haplotype_1.csv\",\n    ],\n    tool_hap2_cna_files=[\n        \"/path/to/signals/haplotype_2.csv\",\n        \"/path/to/seacon/haplotype_2.csv\",\n    ],\n    tool_names=[\"signals\", \"seacon\"],\n    changes_file=\"/path/to/gt/changes.csv\",\n)\n\n# 7. Haplotype Phasing Accuracy\nbench.hcPhasing(\n    tool_hap1_cna_files=[\n        \"/path/to/signals/haplotype_1.csv\",\n        \"/path/to/seacon/haplotype_1.csv\",\n    ],\n    tool_hap2_cna_files=[\n        \"/path/to/signals/haplotype_2.csv\",\n        \"/path/to/seacon/haplotype_2.csv\",\n    ],\n    tool_names=[\"signals\", \"seacon\"],\n    ground_truth_hap1_file=\"/path/to/gt/haplotype_1.csv\",\n    ground_truth_hap2_file=\"/path/to/gt/haplotype_2.csv\",\n)\n\n# 8. Mirror-Subclone Benchmark\nbench.mirrorsubclone(\n    tool_cna_files=[\n        \"/path/to/signals/haplotype_combined.csv\",\n        \"/path/to/seacon/haplotype_combined.csv\",\n    ],\n    tool_names=[\"signals\", \"seacon\"],\n    changes_file=\"/path/to/gt/mirrored_clones.csv\",\n)\n</code></pre>"},{"location":"gtbench/cellprofile/","title":"cellprofile","text":""},{"location":"gtbench/cellprofile/#function","title":"Function","text":"<pre><code>cellprofile(\n    self,\n    tool_cna_files: List[str],\n    tool_names: List[str],\n    outfile: str = \"unique_cell_profile.csv\"\n) -&gt; None\n</code></pre> <p>This function counts the number of unique cells contained in each tool\u2019s CNA result file and exports a summary table to <code>self.output_dir</code>.</p>"},{"location":"gtbench/cellprofile/#parameters","title":"Parameters","text":"Name Type Description <code>tool_cna_files</code> <code>List[str]</code> List of CNA result file paths produced by different tools. Must be aligned with <code>tool_names</code> by order. <code>tool_names</code> <code>List[str]</code> List of tool names. Used as the row index in the output table. Must have the same length as <code>tool_cna_files</code>. <code>outfile</code> <code>str</code> The name of the output CSV file. Defaults to <code>\"unique_cell_profile.csv\"</code>."},{"location":"gtbench/cellprofile/#output","title":"Output","text":"<p>The function writes a single CSV file:</p> <ul> <li>Path: <code>os.path.join(self.output_dir, outfile)</code></li> <li>Columns:</li> <li><code>unique_cells_profile</code>: the number of unique cells for each tool</li> <li>Index:</li> <li><code>Tool</code>: tool name (from <code>tool_names</code>)</li> </ul> <p>Example output (<code>unique_cell_profile.csv</code>):</p> <pre><code>Tool,unique_cells_profile\nCHISEL,1099\nAlleloscope,1050\nSIGNALS,980\n</code></pre>"},{"location":"gtbench/cellprofile/#example","title":"Example","text":"<pre><code>rom hcbench.gtbench import gtbench\n\nrunner = gtbench.GTBench(output_dir=\"out/gt_output/\")\n\ntool_cna_files = [\n    \"out/chisel/haplotype_combined.csv\",\n    \"out/signals/haplotype_combined.csv\",\n    \"out/alleloscope/haplotype_combined.csv\",\n]\ntool_names = [\"CHISEL\", \"SIGNALS\", \"Alleloscope\"]\n\nrunner.cellprofile(\n    tool_cna_files=tool_cna_files,\n    tool_names=tool_names,\n    outfile=\"unique_cell_profile.csv\"\n)\n</code></pre>"},{"location":"gtbench/cloneSizebycellprofile/","title":"cloneSizebycellprofile","text":"<p>Function</p>"},{"location":"gtbench/cloneSizebycluster/","title":"cloneSizebycluster","text":""},{"location":"gtbench/cloneSizebycluster/#function","title":"Function","text":"<pre><code>cloneSizebycluster(\n    self,\n    gt_cluster_file: str,\n    tool_cluster_files: List[str],\n    tool_names: List[str],\n    outfile: str = \"clone_size_by_cluster.csv\",\n) -&gt; pd.DataFrame\n</code></pre> <p>This function evaluates the consistency of clone size predictions across different tools compared to a Ground Truth (GT) reference. </p> <ul> <li>Result: Groups the results by the GT <code>cluster_size</code> and calculates the mean predicted size for each group to identify scaling trends or biases.</li> </ul>"},{"location":"gtbench/cloneSizebycluster/#parameters","title":"Parameters","text":"Name Type Description <code>gt_cluster_file</code> <code>str</code> Path to the Ground Truth CSV file containing cluster assignments. <code>tool_cluster_files</code> <code>List[str]</code> A list of file paths to the <code>clusters.csv</code> files generated by each tool. <code>tool_names</code> <code>List[str]</code> A list of tool names corresponding to the <code>tool_cluster_files</code> (must match in length and order). <code>outfile</code> <code>str</code> The name of the detailed output CSV file. Defaults to <code>\"clone_size_by_cluster.csv\"</code>."},{"location":"gtbench/cloneSizebycluster/#input-file-format","title":"Input File Format","text":""},{"location":"gtbench/cloneSizebycluster/#cluster-files","title":"Cluster Files","text":"<p>Both the <code>gt_cluster_file</code> and each entry in <code>tool_cluster_files</code> are expected to be CSV files.</p> <pre><code>cell_id,clone_id\ncell_001,A\ncell_002,A\ncell_003,B\n</code></pre>"},{"location":"gtbench/cloneSizebycluster/#output","title":"Output","text":"<p>The function writes two CSV files to <code>self.output_dir</code>:</p> <ol> <li>Detailed Table: <code>{self.output_dir}/{outfile}</code></li> </ol> <p>Contains the raw comparison of sizes for every individual across all tools.</p> <ol> <li>Summary Table: <code>{self.output_dir}/mean_{outfile}</code></li> </ol> <p>Contains the averaged results grouped by GT cluster.</p> Column Meaning <code>cluster_size</code> The actual size of the clones in the Ground Truth. <code>{Tool}_pred_size</code> The average size predicted by the specific tool for clones of that GT size."},{"location":"gtbench/cloneSizebycluster/#example","title":"Example","text":"<pre><code>from hcbench.gtbench import gtbench\n\n# Initialize the runner\ngtbench_runner = gtbench.GTBench(output_dir=\"out/gt_output/\")\n\n# Define inputs\ngt_path = \"/home/jianganna/workspace/HCDSIM/data/new-gt/clusters.csv\"\ntool_files = [\n    \"out/chisel/clusters.csv\",\n    \"out/signals/clusters.csv\"\n]\ntool_names = [\"CHISEL\", \"SIGNALS\"]\n\n# Execute analysis\ngtbench_runner.cloneSizebycluster(\n    gt_cluster_file=gt_path,\n    tool_cluster_files=tool_files,\n    tool_names=tool_names,\n    outfile=\"comparison_results.csv\"\n)\n\n# Example output:\n#    cluster_size  CHISEL_pred_size  SIGNALS_pred_size\n# 0            50              48.2               51.5\n# 1           200             185.0              205.2\n</code></pre>"},{"location":"gtbench/clusterConsistency/","title":"clusterConsistency","text":""},{"location":"gtbench/clusterConsistency/#function","title":"Function","text":"<pre><code>clusterConsistency(\n    tool_clone_files: List[str],\n    tool_names: List[str],\n) -&gt; pd.DataFrame\n</code></pre> <p>For each tool, the function loads  <code>clusters.csv</code>file and calculates:</p> <ul> <li>ARI: Adjusted Rand Index between <code>cell_id</code> and <code>clone_id</code></li> <li>AMI: Adjusted Mutual Information between <code>cell_id</code> and <code>clone_id</code></li> </ul> <p>It aggregates results across tools into a single table, writes it to:</p> <ul> <li><code>{self.output_dir}/clustering_result.csv</code></li> </ul> <p>and returns the result as a DataFrame.</p>"},{"location":"gtbench/clusterConsistency/#parameters","title":"Parameters","text":"Name Type Description <code>tool_clone_files</code> <code>List[str]</code> List of file paths, one per tool. Each file should be a CSV containing at least <code>cell_id</code> and <code>clone_id</code> columns. <code>tool_names</code> <code>List[str]</code> List of tool names aligned with <code>tool_clone_files</code> (same length and order)."},{"location":"gtbench/clusterConsistency/#input-file-format","title":"Input File Format","text":"<p>Each <code>tool_clone_files[i]</code> is expected to be a CSV with at least:</p> <ul> <li><code>cell_id</code>: string cell identifier, expected format like <code>\"&lt;cluster&gt;_&lt;rest&gt;\"</code> so that <code>cell_id.split(\"_\")[0]</code> yields the reference cluster label</li> <li><code>clone_id</code>: clone assignment label from the tool</li> </ul> <p>Example:</p> <pre><code>cell_id,clone_id\nA_cell0001,1\nA_cell0002,1\nB_cell0003,2\n</code></pre> <p>From this, the function derives:</p> <ul> <li><code>clusters1 = [\"A\", \"A\", \"B\"]</code></li> <li><code>clusters2 = [\"1\", \"1\", \"2\"]</code></li> </ul>"},{"location":"gtbench/clusterConsistency/#return-type","title":"Return Type","text":"<ul> <li><code>pd.DataFrame</code></li> </ul>"},{"location":"gtbench/clusterConsistency/#returns","title":"Returns","text":"<p>A DataFrame with one row per tool:</p> Column Meaning <code>Tool</code> Tool name from <code>tool_names</code> <code>ARI</code> Adjusted Rand Index between derived clusters and <code>clone_id</code> <code>AMI</code> Adjusted Mutual Information between derived clusters and <code>clone_id</code>"},{"location":"gtbench/clusterConsistency/#output","title":"Output","text":"<ul> <li>Writes a CSV summary to:   <code>os.path.join(self.output_dir, \"clustering_result.csv\")</code></li> </ul>"},{"location":"gtbench/clusterConsistency/#example","title":"Example","text":"<pre><code>from hcbench.gtbench import gtbench\n\n# Suppose self.output_dir = \"out/gt_output\"\n\ngtbench_runner = gtbench.GTBench(\n    output_dir=f\"out/gt_output/\")\n\ntool_clone_files = [\n    \"out/chisel/clusters.csv\",\n    \"out/alleloscope/clusters.csv\",\n    \"out/signals/clusters.csv\",\n]\ntool_names = [\"CHISEL\", \"Alleloscope\", \"SIGNALS\"]\n\n# Call from within your class instance that has self.output_dir (out/gt_output/) defined\ndf = gtbench_runner.clusterConsistency(\n    tool_clone_files=tool_clone_files,\n    tool_names=tool_names,\n)\n\nprint(df)\n# Expected output (values are illustrative):\n#           Tool     ARI     AMI\n# 0       CHISEL  0.230   0.301\n# 1  Alleloscope  0.5321  0.4880\n# 2      SIGNALS  0.8123  0.7451\n</code></pre> <p>After running, you will also find:</p> <pre><code>out/gt_output/clustering_result.csv\n</code></pre> <p>containing the same summary table.</p>"},{"location":"gtbench/other/","title":"Other","text":""},{"location":"gtbench/other/#submodule-descriptions","title":"Submodule Descriptions","text":""},{"location":"gtbench/other/#1-cndetect","title":"1. cndetect","text":"<p>Calculates RMSE, ACC, and SCC for evaluating CN detection at the bin level.  It compares predicted CN profiles from different tools to the ground truth.</p> <p>Output: <code>bin_level_results.csv</code></p>"},{"location":"gtbench/other/#2-cnclass","title":"2. cnclass","text":"<p>Evaluates the accuracy of CN state classification across bins.  Supports both <code>acCNA</code> and <code>hcCNA</code> modes and computes AUROC, AUPRC, accuracy, precision, recall, and F1 score for each tool.</p> <p>Output: Categorized CNV CSV files and evaluation summary tables.</p>"},{"location":"gtbench/other/#3-hccnchange","title":"3. hccnchange","text":"<p>Determines whether CN changes between parent and child clones are correctly identified.  Evaluates the Root Mean Squared Error (RMSE) and Accuracy (ACC) for each tool.</p> <p>Output: <code>evolution_onset_CN_Change.csv</code></p>"},{"location":"gtbench/other/#4-hccnstable","title":"4. hccnstable","text":"<p>Computes Evolutionary CN Stability based on phylogenetic tree relationships between clones.  Requires both maternal/paternal CNA files and a <code>tree.newick</code> file describing clone hierarchy.</p> <p>Output: <code>evolution_cn_stability_acc.csv</code></p>"},{"location":"gtbench/other/#5-hconsetccc","title":"5. hconsetccc","text":"<p>Determines whether CN events are correctly detected at their first evolutionary branch.  This submodule evaluates accuracy (ACC) across DEL/DUP events.</p> <p>Output: <code>evolution_onset_acc.csv</code></p>"},{"location":"gtbench/other/#6-hconsetcn","title":"6. hconsetcn","text":"<p>Assesses whether parental CN states are correctly inferred during evolution.  Evaluates both RMSE and ACC.</p> <p>Output: <code>evolution_onset_parent_CN.csv</code></p>"},{"location":"gtbench/other/#7-hcphasing","title":"7. hcphasing","text":"<p>Quantifies haplotype phasing accuracy using two metrics:</p> <ul> <li>Mismatch Error: Fraction of individual loci where predicted haplotypes differ from the ground truth.</li> <li>Switch Error: Frequency of phase switches between consecutive loci.</li> </ul> <p>Output: <code>hcPhasing.csv</code></p>"},{"location":"gtbench/other/#8-mirrorsubclone","title":"8. mirrorsubclone","text":"<p>Evaluates accuracy of detecting mirror-subclone CNAs, using RMSE and ACC.  Mirror-subclones are pairs of subclones that exhibit complementary CNA patterns.</p> <p>Output: <code>mirror_subclone_result.csv</code></p>"},{"location":"gtbench/other/#9-subdetect","title":"9. subdetect","text":"<p>Calculates Adjusted Mutual Information (AMI) and Adjusted Rand Index (ARI) to measure clustering accuracy of predicted clone structures.  Each classification file should contain <code>cell_id</code> and <code>clone_id</code> columns.</p> <p>Output: <code>AMI_ARI_results.csv</code></p>"},{"location":"parsers/","title":"Overview","text":""},{"location":"parsers/#hcbench-parsers","title":"\ud83e\uddec HCBench Parsers","text":"<p>Welcome to the HCBench Parser Suite \u2014 a unified framework for standardizing single-cell copy number alteration (CNA) outputs from multiple tools.</p> <p>Each parser converts heterogeneous output formats from different algorithms (CHISEL, Alleloscope, CNRein, SEACON, and SIGNALS) into a single consistent format suitable for downstream benchmarking and visualization.</p>"},{"location":"parsers/#common-standardized-outputs","title":"\ud83c\udfaf Common Standardized Outputs","text":"<p>While each tool requires different input files and formats, every parser in this suite is designed to output a canonical directory structure. Depending on the specific methods called, a fully processed output directory will typically contain:</p> <p>CNA Matrices: <code>haplotype_combined.csv</code>, or split <code>minor.csv</code>, <code>major.csv</code>, and <code>minor_major.csv</code> matrices (regions \u00d7 cells).</p> <p>Cluster Mapping: <code>clusters.csv</code> containing standardized <code>cell_id</code> and <code>clone_id</code> columns.</p> <p>Bin Counts / RDR: <code>bin_counts.csv</code> or <code>bin_rdr.csv</code> formatted as a wide matrix of regions by cells.</p> <p>Sparse VAF Matrices: A <code>VAF/</code> directory containing standard Matrix Market (<code>.mtx</code>) files for Allelic Depth (AD) and Read Depth (DP).</p>"},{"location":"parsers/#parsers-overview","title":"\ud83d\udcd6 Parsers Overview","text":"Parser Main Input Additional Inputs Format Types Supported Outputs CHISEL <code>calls.tsv</code> <code>mapping.tsv</code>, VAF table Tab-delimited text CNA Matrix, Clusters, Bin Counts, Sparse VAF Alleloscope <code>.rds</code> files <code>clusters.csv</code>, raw counts TSV, cellSNP directory R serialized data, TSV, CSV CNA Matrix, Clusters, Bin Counts, Sparse VAF CNRein <code>CNReinPrediction.csv</code> <code>.npz</code> arrays, split VCF files CSV, NPZ, VCF CNA Matrix, Bin RDR, Sparse VAF SEACON <code>calls.tsv</code> <code>counts.tsv</code>, <code>vaf.tsv</code> Tab-delimited text Split CNA Matrices, Bin Counts, Sparse VAF SIGNALS <code>hscn.rds</code> (exported to <code>.tsv</code>) cluster file, bin counts, VAF table Tab-delimited text / CSV CNA Matrix, Clusters, Bin Counts, Sparse VAF <p>All parsers generate outputs in the same canonical structure, making it possible to directly compare results across tools in the HCBench benchmarking pipeline.</p>"},{"location":"parsers/alleloscope/","title":"Alleloscope Parser","text":"<p>This module provides <code>AlleloscopeParser</code>, specialized for parsing Alleloscope outputs and exporting standardized matrices and helper files used by hcbench workflows.</p> <p>Key features:</p> <ul> <li>Read Alleloscope RDS outputs (genotypes and segmentation table) and convert them into a unified haplotype level CNA matrix</li> <li>Optional region splitting by a user defined <code>bin_size</code></li> <li>Parse Alleloscope cluster assignments into a standardized <code>clusters.csv</code></li> <li>Export bin-level count matrices as <code>bin_counts.csv</code></li> <li>Convert a cellSNP-like VAF long table into sparse matrix outputs</li> </ul>"},{"location":"parsers/alleloscope/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"parsers/alleloscope/#1-parse-the-cna-matrix-from-rds","title":"\ud83e\uddec 1. Parse the CNA Matrix from RDS","text":"<pre><code>from hcbench.parsers.alleloscope import AlleloscopeParser\n\nallelo_output = \"/output/alleloscope/\"\ngenotypes_rds = \"/demo_output/alleloscope/output/rds/genotypes.rds\"\nseg_table_rds = \"/demo_output/alleloscope/output/rds/seg_table.rds\"\n\nalleloscope_parser = AlleloscopeParser(\n    output_path=allelo_output,\n    genotypes_rds_path=genotypes_rds,\n    seg_table_rds_path=seg_table_rds,\n    barcode_path=None,\n    bin_size=100000,          # set an integer to split regions, e.g. 100000\n    start_offset=1,         # shift start coordinate by +1 if needed\n)\n\nalleloscope_parser.run()\n</code></pre> <p>After running, the parser will read the two RDS files and save results to the output directory, typically containing files, for example:</p> <pre><code>/output/alleloscope/\n  haplotype_combined.csv\n  haplotype_1.csv\n  haplotype_2.csv\n  minor.csv\n  major.csv\n  minor_major.csv\n</code></pre>"},{"location":"parsers/alleloscope/#2-parse-the-cluster-file","title":"\ud83e\uddec 2. Parse the Cluster File","text":"<pre><code>cluster_file = \"/demo_output/alleloscope/output/clusters.csv\"\nalleloscope_parser.get_cluster(cluster_file)\n</code></pre> <p>After running this command, the following standardized file will be created:</p> <pre><code>/output/alleloscope/\n  clusters.csv\n</code></pre> <p>with content:</p> <pre><code>cell_id,clone_id\ncellA,1\ncellB,1\ncellC,2\n</code></pre>"},{"location":"parsers/alleloscope/#3-parse-the-bin-counts-matrix","title":"\ud83e\uddec 3. Parse the bin counts matrix","text":"<pre><code>counts_file = \"/demo_output/alleloscope/input/counts/raw_counts.tsv\"\nalleloscope_parser.get_bin_counts(counts_file)\n</code></pre> <p>After running this command, the following standardized file will be created:</p> <pre><code>/output/alleloscope/\n  bin_counts.csv\n</code></pre>"},{"location":"parsers/alleloscope/#4-parse-the-vaf-sparse-matrices","title":"\ud83e\uddec 4. Parse the VAF sparse matrices","text":"<p>This method assumes <code>vaf_file_path</code> is a directory containing cellSNP style outputs such as:</p> <ul> <li><code>cellSNP.samples.tsv</code></li> <li><code>cellSNP.tag.AD.mtx</code></li> <li><code>cellSNP.tag.DP.mtx</code></li> <li><code>cellSNP.base.vcf.gz</code></li> </ul> <pre><code>alleloscope_parser.get_VAF_matrix(\n    vaf_file_path=\"/demo_output/alleloscope/cellSNP_out\",\n    min_dp=3,\n    min_cells=10,\n    prefix=\"cellSNP\",\n)\n</code></pre> <p>Output:</p> <pre><code>/output/alleloscope/\n  VAF/\n    cellSNP.VAF.filtered.mtx\n    ...\n</code></pre>"},{"location":"parsers/alleloscope/#initialization","title":"\u2699\ufe0f Initialization","text":"<pre><code>AlleloscopeParser(\n    output_path: str,\n    genotypes_rds_path: str,\n    seg_table_rds_path: str,\n    barcode_path: str | None = None,\n    bin_size: int | None = None,\n    add_chr_prefix: bool = True,\n    start_offset: int = 1,\n    **kwargs\n)\n</code></pre> <p><code>output_path</code> : base output directory.</p> <p><code>genotypes_rds_path</code> : Path to the Alleloscope genotypes RDS file.</p> <p><code>seg_table_rds_path</code>: Path to the Alleloscope segmentation table RDS file. It is used to map region identifiers into standardized region labels like:</p> <ul> <li><code>chr&lt;CHR&gt;:&lt;START+start_offset&gt;-&lt;END&gt;</code> when <code>add_chr_prefix=True</code></li> <li><code>&lt;CHR&gt;:&lt;START+start_offset&gt;-&lt;END&gt;</code> when <code>add_chr_prefix=False</code></li> </ul> <p><code>barcode_path</code> (optional) :Path to a barcode mapping file used to remap cell IDs</p> <p><code>bin_size</code> (optional) :If set, regions are split into fixed sized. </p> <p><code>add_chr_prefix</code> (default <code>True</code>) :Controls whether to prepend <code>\"chr\"</code> when forming the region label from the segmentation table.</p> <p><code>start_offset</code> (default <code>1</code>) :Adds an offset to the start coordinate when forming region labels.</p>"},{"location":"parsers/alleloscope/#core-methods","title":"\ud83e\udde0 Core Methods","text":""},{"location":"parsers/alleloscope/#alleloscopeparserrun","title":"<code>AlleloscopeParser.run()</code>","text":"<p>Executes the standard pipeline for the CNA matrix:</p> <ul> <li>Reads the provided <code>genotypes_rds_path</code> and <code>seg_table_rds_path</code>.</li> <li>Standardizes genomic regions based on <code>start_offset</code> and <code>add_chr_prefix</code>.</li> <li>Optionally splits regions into smaller bins if <code>bin_size</code> is provided.</li> <li>Writes the unified haplotype matrices directly into <code>output_path</code>.</li> </ul>"},{"location":"parsers/alleloscope/#alleloscopeparserget_clustercluster_file_path","title":"<code>AlleloscopeParser.get_cluster(cluster_file_path)</code>","text":"<p>Parses an Alleloscope cluster mapping file and writes a standardized CSV.</p> <p>Input</p> <ul> <li><code>cluster_file_path</code>: CSV file containing at least the cell identifiers and their corresponding cluster/clone IDs.</li> </ul> <p>Output writes to:</p> <ul> <li><code>{self.output_path}/clusters.csv</code>, ensuring <code>cell_id</code> and <code>clone_id</code> column formatting.</li> </ul>"},{"location":"parsers/alleloscope/#alleloscopeparserget_bin_countscounts_file","title":"<code>AlleloscopeParser.get_bin_counts(counts_file)</code>","text":"<p>Creates a region-by-cell wide matrix of per-bin counts.</p> <p>Input</p> <ul> <li><code>counts_file</code>: Path to the raw bin counts TSV file.</li> </ul> <p>Output writes to:</p> <ul> <li><code>{self.output_path}/bin_counts.csv</code></li> </ul> <p>This is a wide matrix:</p> <ul> <li>rows: <code>region</code></li> <li>columns: cells</li> <li>values: counts</li> </ul>"},{"location":"parsers/alleloscope/#alleloscopeparserget_vaf_matrixvaf_file_path-output_pathnone-min_dp1-min_cells1-prefixcellsnp","title":"<code>AlleloscopeParser.get_VAF_matrix(vaf_file_path, output_path=None, min_dp=1, min_cells=1, prefix=\"cellSNP\")</code>","text":"<p>Converts cellSNP-like VAF outputs into sparse matrix outputs.</p> <p>Input format</p> <p><code>vaf_file_path</code> must be a directory containing cellSNP-style outputs such as:</p> <ul> <li><code>cellSNP.samples.tsv</code></li> <li><code>cellSNP.tag.AD.mtx</code></li> <li><code>cellSNP.tag.DP.mtx</code></li> <li><code>cellSNP.base.vcf.gz</code></li> </ul> <p>Parameters</p> <p><code>output_path</code> (optional)</p> <ul> <li>If provided: outputs under <code>{output_path}/VAF</code>, else outputs under <code>{self.output_path}/VAF</code>.</li> </ul> <pre><code>min_dp\n</code></pre> <ul> <li>Filter low depth sites.</li> </ul> <pre><code>min_cells\n</code></pre> <ul> <li>Filter sites supported by too few cells.</li> </ul> <pre><code>prefix\n</code></pre> <ul> <li>Output file prefix (default: <code>cellSNP</code>).</li> </ul> <p>Output</p> <p>Creates a <code>VAF/</code> directory containing the sparse matrix (<code>.mtx</code>) files.</p>"},{"location":"parsers/alleloscope/#generating-a-cluster-file-in-r","title":"\ud83e\uddec Generating a Cluster File in R","text":"<p>If you wish to generate the Alleloscope clustering file from your processed object in R,  you can use the following commands:</p> <pre><code>linplot = Lineage_plot(Obj_filtered = Obj_filtered, nSNP = 2000, nclust = 10)\nwrite.csv(linplot, file = \"cluster.csv\", row.names = TRUE)\n</code></pre> <p>This will create a <code>cluster.csv</code> file that can be used as input to <code>AlleloscopeParser.get_cluster()</code> in Python.</p>"},{"location":"parsers/chisel/","title":"CHISEL Parser","text":"<p>This module provides ChiselParser, specialized for parsing CHISEL outputs and exporting standardized matrices and helper files used by hcbench workflows.</p> <p>Key features:</p> <ul> <li>Run the existing  pipeline on CHISEL CNA tables</li> <li>Optional two-pass execution to export two different value columns into: <code>clone_level/</code>,<code>cell_level/</code></li> <li>Parse CHISEL cluster assignments into a standardized <code>clusters.csv</code></li> <li>Export bin-level count matrices as <code>bin_counts.csv</code></li> <li>Convert a cellSNP-like VAF long table into sparse matrix outputs</li> </ul>"},{"location":"parsers/chisel/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"parsers/chisel/#1-parse-the-cna-matrix","title":"\ud83e\uddec  1. Parse the CNA Matrix","text":"<pre><code>from hcbench.parsers.chisel import ChiselParser\n\nchisel_input = \"/demo_output/chisel/calls/calls.tsv\"\nchisel_output = \"/output/chisel/\"\n\nchisel_parser = ChiselParser(chisel_input, chisel_output,value_cols=[\"HAP_CN_CLONE\", \"HAP_CN_CELL\"])\nchisel_parser.run()\n</code></pre> <p>After running, the parser will read <code>calls.tsv</code> and results are saved to the output directory, typically containing the following files:</p> <pre><code>/output/chisel/\n\u251c\u2500\u2500 clone-level/\n\u2502   \u2514\u2500\u2500 haplotype_combined.csv\n\u2502   \u2514\u2500\u2500 haplotype_1.csv       \n\u2502   \u2514\u2500\u2500 haplotype_2.csv       \n\u2502   \u2514\u2500\u2500 minor.csv             \n\u2502   \u2514\u2500\u2500 major.csv             \n\u2502   \u2514\u2500\u2500 minor_major.csv\n\u251c\u2500\u2500 cell-level/\n\u2502   \u2514\u2500\u2500 haplotype_combined.csv\n\u2502   \u2514\u2500\u2500 haplotype_1.csv       \n\u2502   \u2514\u2500\u2500 haplotype_2.csv       \n\u2502   \u2514\u2500\u2500 minor.csv             \n\u2502   \u2514\u2500\u2500 major.csv             \n\u2502   \u2514\u2500\u2500 minor_major.csv   \n</code></pre> <ul> <li><code>haplotype_combined.csv</code> \u2014 main CNA matrix (regions \u00d7 cells).   Each value represents the combined haplotype copy number in the form <code>\"hap1|hap2\"</code>.</li> </ul>"},{"location":"parsers/chisel/#2-parse-the-cluster-file","title":"\ud83e\uddec  2. Parse the Cluster File","text":"<p>If you have a CHISEL cluster mapping file (commonly named <code>mapping.tsv</code>), you can parse it separately using the new <code>get_cluster()</code> method:</p> <pre><code>cluster_file = \"/demo_output/chisel/clones/mapping.tsv\"\nchisel_parser.get_cluster(cluster_file)\n</code></pre> <p>An example of <code>mapping.tsv</code>:</p> <pre><code>#CELL    CLUSTER    CLONE\nAAACCTGAGAAGGACA    3233    Clone3233\nAAACCTGAGATCTGCT    1484    Clone1484\nAAACCTGAGTAATCCC    1924    None\nAAACCTGAGTGCTGCC    3233    Clone3233\n\n</code></pre> <p>After running this command, the following standardized file will be created:</p> <pre><code>/output/chisel/\n\u2514\u2500\u2500clusters.csv\n</code></pre> <p>with content:</p> <pre><code>cell_id,clone_id\nAAACCTGAGAAGGACA,3233\nAAACCTGAGATCTGCT,1484\nAAACCTGAGTAATCCC,1924\n</code></pre>"},{"location":"parsers/chisel/#3-parse-the-bin-counts-matrix","title":"\ud83e\uddec 3. Parse the bin counts matrix","text":"<pre><code>chisel_parser.get_bin_counts()\n</code></pre> <p>After running this command, the following standardized file will be created:</p> <pre><code>/output/chisel/\n\u2514\u2500\u2500bin_counts.csv\n</code></pre>"},{"location":"parsers/chisel/#4-parse-the-vaf-sparse-matrices","title":"\ud83e\uddec 4. Parse the VAF sparse matrices","text":"<pre><code>chisel_parser.get_VAF_matrix(\n    vaf_file_path=\"/demo_output/chisel/baf/baf.tsv\",\n    min_dp=3,\n    min_cells=10,\n)\n</code></pre> <p>After running this command, the following standardized file will be created:</p> <pre><code>/output/chisel/\n\u251c\u2500\u2500 VAF/\n\u2502   \u2514\u2500\u2500cellSNP_*.mtx\n</code></pre>"},{"location":"parsers/chisel/#initialization","title":"\u2699\ufe0f Initialization","text":"<pre><code>ChiselParser(\n    input_path: str,\n    output_path: str,\n    barcode_path: str | None = None,\n    value_cols: list[str] | tuple[str, str] | None = None,\n    **kwargs\n)\n</code></pre> <p><code>input_path</code>: Path to the CHISEL CNA output table (long format), the output directory of CHISEL typically looks like this:</p> <pre><code>demo_output/chisel/\n\u251c\u2500\u2500 calls/\n\u2502   \u2514\u2500\u2500 calls.tsv\n</code></pre> <p>An example of <code>calls.tsv</code>:</p> <pre><code>#CHR    START   END CELL    NORM_COUNT  COUNT   RDR A_COUNT B_COUNT BAF CLUSTER HAP_CN  CORRECTED_HAP_CN\nchr1    0   1000000 AAACAGGTACAT    16269   1590    0.7594  76  67  0.4685  55  1|1 1|1\nchr1    0   1000000 AAATTTGCCTTA    16269   3003    1.3324  74  195 0.7249  55  6|2 6|2\nchr1    0   1000000 AACACATCCATC    16269   1587    0.9759  78  78  0.5 55  1|1 1|1\n</code></pre> <p>The required columns are:</p> <pre><code>#CHR, START, END, CELL, CORRECTED_HAP_CN\n</code></pre> <p>\u200b   Please ensure these column names are spelled exactly as shown.</p> <p><code>output_path</code>: base output directory. If <code>value_cols</code> contains two columns, <code>ChiselParser</code> will automatically write to:</p> <ul> <li><code>{output_path}/clone_level</code></li> <li><code>{output_path}/cell_level</code></li> </ul> <p><code>barcode_path</code> (optional): Path to a barcode mapping file used to remap cell. Mapping is applied in:</p> <ul> <li>CNA table</li> <li>cluster table</li> <li>counts table</li> </ul> <p><code>value_cols</code> (optional): Enables two-pass execution. Must be a <code>list</code>/<code>tuple</code> of length 2, e.g.:</p> <pre><code>  value_cols=['CORRECTED_HAP_CN','HAP_CN']\n</code></pre> <ul> <li><code>value_cols[0]</code> \u2192 written under <code>clone_level/</code></li> <li><code>value_cols[1]</code> \u2192 written under <code>cell_level/</code></li> </ul> <p>If not provided, the parser runs once using the default <code>value_col = \"HAP_CN\"</code>.</p>"},{"location":"parsers/chisel/#core-methods","title":"\ud83e\udde0 Core Methods","text":""},{"location":"parsers/chisel/#chiselparserrun","title":"<code>ChiselParser.run()</code>","text":"<ul> <li>Legacy mode (default): if <code>value_cols</code> is not provided (or only one column is configured), it runs once:</li> <li>Uses <code>self.value_col</code> (default: <code>HAP_CN</code>)</li> <li>Writes into <code>output_path</code></li> <li>Two-pass mode: if <code>value_cols</code> has length 2, it runs twice:</li> <li><code>self.value_col = value_cols[0]</code> \u2192 <code>output_path/clone_level</code></li> <li><code>self.value_col = value_cols[1]</code> \u2192 <code>output_path/cell_level</code></li> </ul>"},{"location":"parsers/chisel/#chiselparserget_clustercluster_file_path","title":"<code>ChiselParser.get_cluster(cluster_file_path)</code>","text":"<p>Parses a CHISEL cluster mapping file and writes a standardized CSV.</p> <p>Input</p> <ul> <li><code>cluster_file_path</code>: TSV file containing at least:<code>#CELL</code>,<code>CLUSTER</code></li> </ul> <p>Output writes to:</p> <ul> <li><code>{self.output_path}/clusters.csv</code>, for example: </li> </ul> column meaning cell_id cell identifier (possibly remapped) clone_id CHISEL cluster/clone label"},{"location":"parsers/chisel/#chiselparserget_bin_counts","title":"<code>ChiselParser.get_bin_counts()</code>","text":"<p>Creates a region-by-cell wide matrix of per-bin counts.</p> <p>Output writes to:</p> <ul> <li><code>{self.output_path}/bin_counts.csv</code></li> </ul> <p>This is a wide matrix:</p> <ul> <li>rows: <code>region</code> (e.g., <code>chr1:1000-2000</code>)</li> <li>columns: cells</li> <li>values: counts</li> </ul>"},{"location":"parsers/chisel/#chiselparserget_vaf_matrixvaf_file_path-output_pathnone-min_dp1-min_cells1-prefixcellsnp","title":"<code>ChiselParser.get_VAF_matrix(vaf_file_path, output_path=None, min_dp=1, min_cells=1, prefix=\"cellSNP\")</code>","text":"<p>Converts a cellSNP-like VAF long table into sparse matrix outputs using <code>long_to_mtx()</code>.</p> <p>Input format</p> <p><code>vaf_file_path</code> must be a tab-separated file with no header and exactly 5 columns:</p> column index meaning 0 chromosome 1 genomic position 2 cell identifier 3 allele A count 4 allele B count <p>Parameters</p> <p><code>output_path</code> (optional)</p> <ul> <li>If provided: outputs under <code>{output_path}/VAF</code>, else: outputs under <code>{self.output_path}/VAF</code></li> </ul> <p><code>min_dp</code></p> <ul> <li>filter low depth (typically <code>Acount + Bcount</code>)</li> </ul> <p><code>min_cells</code></p> <ul> <li>filter sites supported by too few cells</li> </ul> <p><code>prefix</code></p> <ul> <li>output file prefix (default: <code>cellSNP</code>)</li> </ul> <p>Output</p> <p>Creates a <code>VAF/</code> directory containing files:</p> <pre><code>.../VAF/\n\u2514\u2500\u2500cellSNP_*.mtx\n</code></pre>"},{"location":"parsers/cnrein/","title":"CNRein Parser","text":"<p>This module provides <code>CNReinParser</code>, specialized for parsing CNRein outputs and exporting standardized matrices and helper files used by hcbench workflows.</p> <p>Key features:</p> <ul> <li>Read CNRein prediction tables and merge separate haplotype columns into a unified haplotype-level CNA matrix</li> <li>Optional region splitting by a user-defined <code>bin_size</code></li> <li>Extract bin-level Read Depth Ratio (RDR) from <code>.npz</code> files into a standardized <code>bin_rdr.csv</code></li> <li>Convert a directory of separate chromosome VCF files into sparse VAF matrix outputs</li> </ul>"},{"location":"parsers/cnrein/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"parsers/cnrein/#1-parse-the-cna-matrix","title":"\ud83e\uddec 1. Parse the CNA Matrix","text":"<p>Python</p> <pre><code>from hcbench.parsers.cnrein import CNReinParser\n\ncnrein_input = \"/demo_output/cnrein/finalPrediction/CNReinPrediction.csv\"\ncnrein_output = \"/output/cnrein/\"\n\ncnrein_parser = CNReinParser(\n    input_path=cnrein_input,\n    output_path=cnrein_output,\n)\n\ncnrein_parser.run()\n</code></pre> <p>After running, the parser will read the input table, merge the <code>Haplotype 1</code> and <code>Haplotype 2</code> columns into a <code>HAP_CN</code> column, and save the standardized files to the output directory:</p> <p>Plaintext</p> <pre><code>/output/cnrein/\n\u251c\u2500\u2500 haplotype_combined.csv\n\u251c\u2500\u2500 haplotype_1.csv       \n\u251c\u2500\u2500 haplotype_2.csv       \n\u251c\u2500\u2500 minor.csv             \n\u251c\u2500\u2500 major.csv             \n\u2514\u2500\u2500 minor_major.csv       \n</code></pre> <ul> <li><code>haplotype_combined.csv</code> \u2014 main CNA matrix (regions \u00d7 cells).</li> </ul> <p>Each value represents the combined haplotype copy number in the form <code>\"hap1|hap2\"</code>.</p>"},{"location":"parsers/cnrein/#2-parse-the-bin-rdr-matrix","title":"\ud83e\uddec 2. Parse the bin RDR matrix","text":"<p>Unlike parsers that extract counts from a text file, CNRein stores RDR  and cell names in numpy <code>.npz</code> arrays.</p> <pre><code>counts_file = \"/demo_output/cnrein//binScale/filtered_RDR_avg.npz\"\ncells_file = \"/demo_output/cnrein/initial/cellNames.npz\"\n\ncnrein_parser.get_bin_rdr(\n    counts_path=counts_file, \n    cell_name_path=cells_file\n)\n</code></pre> <p>After running this command, the following standardized file will be created:</p> <p>Plaintext</p> <pre><code>/output/cnrein/\n\u2514\u2500\u2500 bin_rdr.csv\n</code></pre>"},{"location":"parsers/cnrein/#3-parse-the-vaf-sparse-matrices","title":"\ud83e\uddec 3. Parse the VAF sparse matrices","text":"<p>This method expects <code>vaf_file_dir</code> to be a directory containing 22 separate chromosome VCF files named precisely as <code>seperates_chr1.vcf.gz</code> through <code>seperates_chr22.vcf.gz</code>.</p> <pre><code>cnrein_parser.get_VAF_matrix(\n    vaf_file_dir=\"/demo_output/cnrein/vcf_output/\",\n    min_dp=3,\n    min_cells=10,\n    prefix=\"cellSNP\"\n)\n</code></pre> <p>After running this command, the following standardized directory and Matrix Market files will be created:</p> <p>Plaintext</p> <pre><code>/output/cnrein/\n\u251c\u2500\u2500 VAF/\n\u2502   \u251c\u2500\u2500 cellSNP_AD.mtx\n\u2502   \u251c\u2500\u2500 cellSNP_DP.mtx\n\u2502   \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"parsers/cnrein/#initialization","title":"\u2699\ufe0f Initialization","text":"<pre><code>CNReinParser(\n    input_path: str,\n    output_path: str,\n    chrom_col: str = \"Chromosome\",\n    start_col: str = \"Start\",\n    end_col: str = \"End\",\n    cell_col: str = \"Cell barcode\",\n    value_col: str = \"HAP_CN\",\n    start_offset: int = 0,\n    add_chr_prefix: bool = True,\n    **kwargs\n)\n</code></pre> <p><code>input_path</code>: Path to the CNRein prediction output table.</p> <p>The required columns based on the default configuration are:</p> <pre><code>Chromosome, Start, End, Cell barcode, HAP_CN\n</code></pre> <p><code>output_path</code>: Base output directory where the standardized matrices will be saved.</p>"},{"location":"parsers/cnrein/#core-methods","title":"\ud83e\udde0 Core Methods","text":""},{"location":"parsers/cnrein/#cnreinparserrun","title":"<code>CNReinParser.run()</code>","text":"<p>Executes the standard pipeline for the CNA matrix:</p> <ul> <li>Parses the table dynamically.</li> <li>Writes the reshaped region-by-cell matrices directly into <code>output_path</code>.</li> </ul>"},{"location":"parsers/cnrein/#cnreinparserget_bin_rdrcounts_path-cell_name_path-cna_pathnone","title":"<code>CNReinParser.get_bin_rdr(counts_path, cell_name_path, cna_path=None)</code>","text":"<p>Creates a region-by-cell wide matrix of per-bin Read Depth Ratios (RDR).</p> <p>Input</p> <ul> <li><code>counts_path</code>: Path to an <code>.npz</code> file containing the counts array (expected shape: <code>n_cells, n_bins</code>).</li> <li><code>cell_name_path</code>: Path to an <code>.npz</code> file containing the cell names array (expected shape: <code>n_cells,</code>).</li> <li><code>cna_path</code> (optional): Path to the <code>haplotype_combined.csv</code> file generated by <code>run()</code>. If not provided, it defaults to looking in the <code>output_path</code>. This is used to extract the correct <code>region</code> index.</li> </ul> <p>Output writes to:</p> <ul> <li><code>{self.output_path}/bin_rdr.csv</code></li> </ul> <p>This is a wide matrix:</p> <ul> <li>rows: <code>region</code></li> <li>columns: cells</li> <li>values: RDR counts</li> </ul>"},{"location":"parsers/cnrein/#cnreinparserget_vaf_matrixvaf_file_dir-output_pathnone-min_dp1-min_cells1-prefixcellsnp","title":"<code>CNReinParser.get_VAF_matrix(vaf_file_dir, output_path=None, min_dp=1, min_cells=1, prefix=\"cellSNP\")</code>","text":"<p>Converts split chromosome VCF files into sparse matrix outputs (AD and DP).</p> <p>Input format</p> <p><code>vaf_file_dir</code> must be a directory containing exactly 22 gzipped VCF files named:</p> <ul> <li><code>seperates_chr1.vcf.gz</code></li> <li><code>seperates_chr2.vcf.gz</code></li> <li>...</li> <li><code>seperates_chr22.vcf.gz</code></li> </ul> <p>Parameters</p> <p><code>output_path</code> (optional)</p> <ul> <li>If provided: outputs under <code>{output_path}/VAF</code>, else outputs under <code>{self.output_path}/VAF</code>.</li> </ul> <pre><code>min_dp\n</code></pre> <ul> <li>Filter low depth sites.</li> </ul> <pre><code>min_cells\n</code></pre> <ul> <li>Filter sites supported by too few cells.</li> </ul> <pre><code>prefix\n</code></pre> <ul> <li>Output file prefix (default: <code>cellSNP</code>).</li> </ul> <p>Output</p> <p>Creates a <code>VAF/</code> directory containing the Matrix Market (<code>.mtx</code>) files.</p>"},{"location":"parsers/seacon/","title":"SEACON Parser","text":"<p>This module provides <code>SeaconParser</code>, specialized for parsing SEACON outputs and exporting standardized matrices and helper files used by hcbench workflows.</p> <p>Key features:</p> <ul> <li>Read SEACON CNA tables and automatically preprocess copy number values by replacing commas with pipes (<code>|</code>).</li> <li>generate <code>minor.csv</code>, <code>major.csv</code>, and combined <code>minor_major.csv</code> outputs by default.</li> <li>Export bin-level count matrices as <code>bin_counts.csv</code>, dynamically mapped to the standard regions extracted from the CNA output.</li> <li>Convert a headerless, tab-separated VAF long table into sparse matrix outputs.</li> </ul>"},{"location":"parsers/seacon/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"parsers/seacon/#1-parse-the-cna-matrix","title":"\ud83e\uddec 1. Parse the CNA Matrix","text":"<pre><code>from hcbench.parsers.seacon import SeaconParser\n\nseacon_input = \"/demo_output/seacon/cna_output.tsv\"\nseacon_output = \"/output/seacon/\"\n\nseacon_parser = SeaconParser(\n    input_path=seacon_input, \n    output_path=seacon_output,\n)\nseacon_parser.run()\n</code></pre> <p>After running, the parser will read the input file, split the haplotypes, and save the standardized files to the output directory. The output directory typically contains:</p> <pre><code>/output/seacon/\n\u251c\u2500\u2500 minor.csv             \n\u251c\u2500\u2500 major.csv             \n\u2514\u2500\u2500 minor_major.csv       \n</code></pre> <ul> <li><code>minor_major.csv</code> \u2014 combined CNA matrix (regions \u00d7 cells).</li> </ul> <p>Each value represents the combined haplotype copy number.</p>"},{"location":"parsers/seacon/#2-parse-the-bin-counts-matrix","title":"\ud83e\uddec 2. Parse the bin counts matrix","text":"<p>\u26a0\ufe0f Important: This method requires the <code>minor_major.csv</code> file to already exist in your output directory to properly extract the <code>region</code> index. Ensure you run the main parser pipeline first.</p> <pre><code>counts_file = \"/demo_output/seacon/counts.tsv\"\n\nseacon_parser.get_bin_counts(counts_path=counts_file)\n</code></pre> <p>After running this command, the following standardized file will be created:</p> <pre><code>/output/seacon/\n\u2514\u2500\u2500 bin_counts.csv\n</code></pre>"},{"location":"parsers/seacon/#3-parse-the-vaf-sparse-matrices","title":"\ud83e\uddec 3. Parse the VAF sparse matrices","text":"<p>This method expects a tab-separated VAF file with no header.</p> <p>Python</p> <pre><code>seacon_parser.get_VAF_matrix(\n    vaf_file_path=\"/demo_output/seacon/vaf.tsv\",\n    min_dp=3,\n    min_cells=10,\n    prefix=\"cellSNP\"\n)\n</code></pre> <p>After running this command, the following standardized directory and Matrix Market files will be created:</p> <p>Plaintext</p> <pre><code>/output/seacon/\n\u251c\u2500\u2500 VAF/\n\u2502   \u251c\u2500\u2500 cellSNP_AD.mtx\n\u2502   \u251c\u2500\u2500 cellSNP_DP.mtx\n\u2502   \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"parsers/seacon/#initialization","title":"\u2699\ufe0f Initialization","text":"<p>Python</p> <pre><code>SeaconParser(\n    input_path: str,\n    output_path: str,\n    chrom_col: str = \"chrom\",\n    start_col: str = \"start\",\n    end_col: str = \"end\",\n    cell_col: str = \"cell\",\n    value_col: str = \"CN\",\n    start_offset: int = 0,\n    add_chr_prefix: bool = False,\n    output_haplotype: bool = False,\n    **kwargs\n)\n</code></pre> <p><code>input_path</code>: Path to the SEACON CNA output table.</p> <p>The required columns based on the default configuration are:</p> <pre><code>chrom, start, end, cell, CN\n</code></pre> <p><code>output_path</code>: Base output directory where the standardized matrices will be saved.</p>"},{"location":"parsers/seacon/#core-methods","title":"\ud83e\udde0 Core Methods","text":""},{"location":"parsers/seacon/#seaconparserrun","title":"<code>SeaconParser.run()</code>","text":"<p>Executes the standard pipeline for the CNA matrix:</p>"},{"location":"parsers/seacon/#seaconparserget_bin_countscounts_path","title":"<code>SeaconParser.get_bin_counts(counts_path)</code>","text":"<p>Creates a region-by-cell wide matrix of per-bin counts.</p> <p>Input</p> <ul> <li><code>counts_path</code>: Path to the counts table. The parser expects a table with cells in rows, so it transposes the dataframe automatically.</li> </ul> <p>Output writes to:</p> <ul> <li><code>{self.output_path}/bin_counts.csv</code>.</li> </ul> <p>This is a wide matrix:</p> <ul> <li>rows: <code>region</code> (dynamically matched from <code>minor_major.csv</code>).</li> <li>columns: cells.</li> <li>values: counts.</li> </ul>"},{"location":"parsers/seacon/#seaconparserget_vaf_matrixvaf_file_path-output_pathnone-min_dp1-min_cells1-prefixcellsnp","title":"<code>SeaconParser.get_VAF_matrix(vaf_file_path, output_path=None, min_dp=1, min_cells=1, prefix=\"cellSNP\")</code>","text":"<p>Converts a tab-separated VAF table into sparse matrix outputs using <code>long_to_mtx()</code>.</p> <p>Input format</p> <p><code>vaf_file_path</code> must be a tab-separated file with no header and exactly 5 columns. The parser automatically maps them to:</p> column index meaning 0 <code>chr</code> 1 <code>position</code> 2 <code>cell</code> 3 <code>Acount</code> 4 <code>Bcount</code> <p>Parameters</p> <p><code>output_path</code> (optional)</p> <ul> <li>If provided: outputs under <code>{output_path}/VAF</code>, else outputs under <code>{self.output_path}/VAF</code>.</li> </ul> <pre><code>min_dp\n</code></pre> <ul> <li>Filter low depth sites.</li> </ul> <pre><code>min_cells\n</code></pre> <ul> <li>Filter sites supported by too few cells.</li> </ul> <pre><code>prefix\n</code></pre> <ul> <li>Output file prefix (default: <code>cellSNP</code>).</li> </ul> <p>Output</p> <p>Creates a <code>VAF/</code> directory containing the Matrix Market (<code>.mtx</code>) files.</p>"},{"location":"parsers/seacon/#input-files","title":"\ud83d\udcc2 Input Files","text":"<p>The output directory of SEACON typically includes a single main file containing copy number information for all cells:</p> <pre><code>demo_output/seacon/\n\u2514\u2500\u2500 calls.tsv\n</code></pre> <ul> <li><code>calls.tsv</code> \u2014 the primary SEACON output file containing inferred copy number (CN) states per cell and genomic region.</li> </ul> <p>An example of <code>calls.tsv</code>:</p> <pre><code>cell    chrom   start   end CN\nclone9_cell6    chr1    5000001 10000000    0,2\nclone9_cell6    chr1    15000001    20000000    0,2\nclone9_cell6    chr1    20000001    25000000    0,2\nclone9_cell6    chr1    25000001    30000000    0,2\n</code></pre> <p>The required columns are:</p> <pre><code>chrom, start, end, cell, CN\n</code></pre> <p>Each entry in the <code>CN</code> column may contain comma-separated allele-specific copy numbers (e.g. <code>\"0,2\"</code>).  The parser automatically converts these values to a standardized <code>\"hap1|hap2\"</code> format (e.g. <code>\"0|2\"</code>).</p>"},{"location":"parsers/seacon/#output-files","title":"\ud83d\udce4 Output Files","text":"<p>After parsing, the following file is generated in the specified output directory:</p> <pre><code>haplotype_combined.csv\n</code></pre> <ul> <li><code>haplotype_combined.csv</code> \u2014 standardized CNA matrix (regions \u00d7 cells).    Each value represents the haplotype-level copy number in the format <code>\"hap1|hap2\"</code>.</li> </ul> <p>If <code>split_haplotype=True</code> is enabled in the base class,  the parser will also produce additional derived matrices:</p> <pre><code>haplotype_1.csv\nhaplotype_2.csv\nminor.csv\nmajor.csv\nminor_major.csv\n</code></pre>"},{"location":"parsers/seacon/#key-parameters","title":"\u2699\ufe0f Key Parameters","text":"Parameter Description Default <code>chrom_col</code> Column name for chromosome. <code>\"chrom\"</code> <code>start_col</code> Column name for region start. <code>\"start\"</code> <code>end_col</code> Column name for region end. <code>\"end\"</code> <code>cell_col</code> Column name for cell ID. <code>\"cell\"</code> <code>value_col</code> Column name for copy number value. <code>\"CN\"</code> <code>start_plus_one</code> Whether to shift start coordinates by +1. <code>False</code> <code>add_chr_prefix</code> Whether to enforce <code>\"chr\"</code> prefix on chromosome names. <code>False</code>"},{"location":"parsers/seacon/#example-usage","title":"\ud83d\ude80 Example Usage","text":"<pre><code>from hcbench.parsers.seacon import SeaconParser\n\nseacon_input = \"/demo_output/seacon/calls.tsv\"\nseacon_output = \"/output/seacon/\"\n\nseacon_parser = SeaconParser(\n    input_path=seacon_input,\n    output_path=seacon_output\n)\nseacon_parser.run()\n</code></pre> <p>After running, the parser will read <code>calls.tsv</code>,  convert <code>CN</code> values from <code>\"x,y\"</code> to <code>\"x|y\"</code>,  and save the standardized file:</p> <pre><code>haplotype_combined.csv\n</code></pre> <p>in your output directory.</p>"},{"location":"parsers/signals/","title":"SIGNALS Parser","text":"<p>This module provides <code>SignalsParser</code>, specialized for parsing Signals outputs and exporting standardized matrices and helper files used by hcbench workflows.</p> <p>Key features:</p> <ul> <li>Run the existing pipeline on Signals CNA tables</li> <li>Parse Signals cluster assignments into a standardized <code>clusters.csv</code></li> <li>Export bin-level count matrices as <code>bin_counts.csv</code></li> <li>Convert a VAF long table into sparse matrix outputs</li> </ul>"},{"location":"parsers/signals/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"parsers/signals/#exporting-hscn_datatsv-from-r","title":"\ud83e\uddec Exporting hscn_data.tsv from R","text":"<p>Run the following R code to extract and save the <code>hscn$data</code> component:</p> <pre><code>mnt &lt;- \"/demo_output/signals/output/\"\n\nhscn &lt;- readRDS(\"/demo_output/signals/hscn.rds\")\n\n# Export the data component\nwrite.table(\n  hscn$data,\n  file = paste0(mnt, \"hscn_data.tsv\"),\n  sep = \"\\t\",\n  quote = FALSE,\n  row.names = FALSE\n)\n</code></pre> <p>This will produce the file <code>hscn_data.tsv</code>, which is then used as input for the parser.</p>"},{"location":"parsers/signals/#1-parse-the-cna-matrix","title":"\ud83e\uddec 1. Parse the CNA Matrix","text":"<pre><code>from hcbench.parsers.signals import SignalsParser\n\nsignals_input = \"/demo_output/signals/output/hscn_data.csv\"\nsignals_output = \"/output/signals/\"\n\nsignals_parser = SignalsParser(input_path=signals_input, output_path=signals_output)\nsignals_parser.run()\n</code></pre> <p>After running, the parser will read the input file and results are saved to the output directory, typically containing the following files:</p> <pre><code>/output/signals/\n\u251c\u2500\u2500 haplotype_combined.csv\n\u251c\u2500\u2500 haplotype_1.csv       \n\u251c\u2500\u2500 haplotype_2.csv       \n\u251c\u2500\u2500 minor.csv             \n\u251c\u2500\u2500 major.csv             \n\u2514\u2500\u2500 minor_major.csv\n</code></pre> <ul> <li><code>haplotype_combined.csv</code> \u2014 main CNA matrix (regions \u00d7 cells).</li> </ul>"},{"location":"parsers/signals/#2-parse-the-cluster-file","title":"\ud83e\uddec 2. Parse the Cluster File","text":"<p>If you have a Signals cluster mapping file, you can parse it separately using the <code>get_cluster()</code> method:</p> <pre><code>cluster_file = \"/demo_output/signals/clusters.csv\"\nsignals_parser.get_cluster(cluster_file)\n</code></pre> <p>An example of the input cluster file:</p> <pre><code>cell_id,clone_id\nAAACCTGAGAAGGACA,CloneA\nAAACCTGAGATCTGCT,CloneB\nAAACCTGAGTAATCCC,CloneA\n</code></pre> <p>After running this command, the following standardized file will be created:</p> <pre><code>/output/signals/\n\u2514\u2500\u2500 clusters.csv\n</code></pre>"},{"location":"parsers/signals/#3-parse-the-bin-counts-matrix","title":"\ud83e\uddec 3. Parse the bin counts matrix","text":"<p>Unlike the CHISEL parser, the Signals parser requires the explicit path to the bin counts file:</p> <pre><code>bin_count_file = \"hmmcopy_results/reads.csv.gz\"\nsignals_parser.get_bin_counts(bin_count_file)\n</code></pre> <p>After running this command, the following standardized file will be created:</p> <pre><code>/output/signals/\n\u2514\u2500\u2500 bin_counts.csv\n</code></pre>"},{"location":"parsers/signals/#4-parse-the-vaf-sparse-matrices","title":"\ud83e\uddec 4. Parse the VAF sparse matrices","text":"<pre><code>signals_parser.get_VAF_matrix(\n    vaf_file_path=\"hscn_pipeline_apptainer/results/counthaps/allele_counts_all.csv.gz\",\n    min_dp=3,\n    min_cells=10,\n)\n</code></pre> <p>After running this command, the following standardized directory and files will be created:</p> <pre><code>/output/signals/\n\u251c\u2500\u2500 VAF/\n\u2502   \u2514\u2500\u2500 cellSNP_*.mtx\n</code></pre>"},{"location":"parsers/signals/#initialization","title":"\u2699\ufe0f Initialization","text":"<pre><code>SignalsParser(\n    input_path: str,\n    output_path: str,\n    **kwargs\n)\n</code></pre> <p><code>input_path</code>: Path to the Signals CNA output. An example of the expected input format:</p> <pre><code>chr start   end reads   copy    state   cell_id alleleA alleleB totalcounts BAF state_min   A   B   state_AS_phased state_AS    LOH phase   state_phase state_BAF\n1   5000001 10000000    34762   NA  2   clone1_cell1    677 193 870 0.22183908045977    1   1   1   1|1 1|1 NO  Balanced    Balanced    0.5\n1   20000001    25000000    34200   NA  2   clone1_cell1    639 222 861 0.257839721254355   1   1   1   1|1 1|1 NO  Balanced    Balanced    0.5\n1   30000001    35000000    42510   NA  2   clone1_cell1    807 203 1010    0.200990099009901   1   1   1   1|1 1|1 NO  Balanced    Balanced    0.5\n</code></pre> <p>The required columns are:</p> <pre><code>chr, start, end, cell_id, state_AS_phased\n</code></pre> <p><code>output_path</code>: Base output directory where the standardized matrices will be saved.</p>"},{"location":"parsers/signals/#core-methods","title":"\ud83e\udde0 Core Methods","text":""},{"location":"parsers/signals/#signalsparserrun","title":"<code>SignalsParser.run()</code>","text":"<p>Executes the standard pipeline for the CNA matrix:</p>"},{"location":"parsers/signals/#signalsparserget_clustercluster_file_path","title":"<code>SignalsParser.get_cluster(cluster_file_path)</code>","text":"<p>Parses a Signals cluster mapping file and writes a standardized CSV.</p> <p>Input</p> <ul> <li><code>cluster_file_path</code>: CSV file containing at least the columns: <code>cell_id</code>, <code>clone_id</code>.</li> </ul> <p>Output writes to:</p> <ul> <li><code>{self.output_path}/clusters.csv</code>, strictly retaining these two columns.</li> </ul>"},{"location":"parsers/signals/#signalsparserget_bin_countsbin_count_file_path","title":"<code>SignalsParser.get_bin_counts(bin_count_file_path)</code>","text":"<p>Creates a region-by-cell wide matrix of per-bin counts. Note that this initializes an internal temporary parser specifically configured for the <code>hg38</code> reference genome and targets the <code>reads</code> column without adding chromosome prefixes.</p> <p>Input</p> <ul> <li><code>bin_count_file_path</code>: Path to the raw bin counts CSV file.</li> </ul> <p>Output writes to:</p> <ul> <li><code>{self.output_path}/bin_counts.csv</code></li> </ul> <p>This is a wide matrix:</p> <ul> <li>rows: <code>region</code></li> <li>columns: cells</li> <li>values: counts</li> </ul>"},{"location":"parsers/signals/#signalsparserget_vaf_matrixvaf_file_path-output_pathnone-min_dp1-min_cells1-prefixcellsnp","title":"<code>SignalsParser.get_VAF_matrix(vaf_file_path, output_path=None, min_dp=1, min_cells=1, prefix=\"cellSNP\")</code>","text":"<p>Converts a VAF long table into sparse matrix outputs.</p> <p>Parameters</p> <p><code>output_path</code> (optional)</p> <ul> <li>If provided: outputs under <code>{output_path}/VAF</code>, else outputs under <code>{self.output_path}/VAF</code>.</li> </ul> <pre><code>min_dp\n</code></pre> <ul> <li>Filter low depth sites.</li> </ul> <pre><code>min_cells\n</code></pre> <ul> <li>Filter sites supported by too few cells.</li> </ul> <pre><code>prefix\n</code></pre> <ul> <li>Output file prefix (default: <code>cellSNP</code>).</li> </ul> <p>Output</p> <p>Creates a <code>VAF/</code> directory containing the Matrix Market (<code>.mtx</code>) files:</p> <p>Plaintext</p> <pre><code>.../VAF/\n\u2514\u2500\u2500 cellSNP_*.mtx\n</code></pre>"},{"location":"parsers/signals/#example-of-hscn_datatsv","title":"\ud83e\udde9 Example of hscn_data.tsv","text":"<p>An example of the exported file may look like:</p> <pre><code>chr start   end reads   copy    state   cell_id alleleA alleleB totalcounts BAF state_min   A   B   state_AS_phased state_AS    LOH phase   state_phase state_BAF\n1   5000001 10000000    34762   NA  2   clone1_cell1    677 193 870 0.22183908045977    1   1   1   1|1 1|1 NO  Balanced    Balanced    0.5\n1   20000001    25000000    34200   NA  2   clone1_cell1    639 222 861 0.257839721254355   1   1   1   1|1 1|1 NO  Balanced    Balanced    0.5\n1   30000001    35000000    42510   NA  2   clone1_cell1    807 203 1010    0.200990099009901   1   1   1   1|1 1|1 NO  Balanced    Balanced    0.5\n</code></pre> <p>Each row corresponds to one genomic bin in a given single cell.</p> <p>The *required columns* are:</p> <p>```</p> <p>chr,start,end,cell_id,state_AS_phased</p> <p>```</p>"}]}